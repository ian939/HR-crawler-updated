name: Saramin Scraper Update

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *' # 매일 자정에 자동 실행 (선택 사항)

permissions:
  contents: write # 저장소에 글을 쓸 수 있는 권한 허용

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium webdriver-manager pandas

    - name: Run Scraper
      run: python scraper.py

    - name: Commit and Push changes # 4) CSV 파일을 바로 깃허브에 업로드
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        git add saramin_results.csv
        git diff-index --quiet HEAD || git commit -m "Update job postings [$(date +'%Y-%m-%d')]"
        git push
